{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5*np.sum((y-t)**2)\n",
    "x=np.arange(0.001,1,0.01)\n",
    "y=np.log(x)\n",
    "plt.plot(x,y)\n",
    "def cross_entropy_error(y,t):\n",
    "    delta=1e-7\n",
    "    return -np.sum(t*np.log(y+delta))\n",
    "def cross_entropy_error_batch(y,t):\n",
    "    if y.ndim==1:\n",
    "        t=t.reshape(1,-1)\n",
    "        y=y.reshape(1,-1)\n",
    "    batch_size=y.shape[0]\n",
    "    return -np.sum(t*np.log(y+1e-7))/batch_size\n",
    "def cross_entropy_error_batch_one_hot(y,t):\n",
    "    if y.ndim==1:\n",
    "        t=t.reshape(1,-1)\n",
    "        y=y.reshape(1,-1)\n",
    "    batch_size=y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]))/batch_size\n",
    "def numerical_diff1(f,x):\n",
    "    h=10e-50\n",
    "    return (f(x+h))/h\n",
    "def numerical_diff(f,x):\n",
    "    h=1e-4\n",
    "    return (f(x+h)-f(x-h))/(2*h)\n",
    "#y = 0.01*x**2+0.1*x\n",
    "def f(x):\n",
    "    return 0.01*x**2+0.1*x\n",
    "x=np.arange(-10,20,0.2)\n",
    "plt.plot(x,f(x))\n",
    "numerical_diff(f,5)\n",
    "def line1(x):\n",
    "    k=numerical_diff(f,5)\n",
    "    y=k*(x-5)+f(5)\n",
    "    return y\n",
    "x1=np.arange(0,20,0.2)\n",
    "plt.plot(x1,line1(x1))\n",
    "plt.plot(x,f(x))\n",
    "def numerical_gradient(f,x):\n",
    "    h=1e-4\n",
    "    grad=np.zeros_like(x)\n",
    "    for idx in range(x.size):\n",
    "        tam_val=x[idx]\n",
    "        x[idx]=tam_val+h\n",
    "        fxh1=f(x)\n",
    "        \n",
    "        x[idx]=tam_val-h\n",
    "        fxh2=f(x)\n",
    "        \n",
    "        grad[idx]=(fxh1-fxh2)/(2*h)\n",
    "        x[idx]=tam_val\n",
    "    return grad\n",
    "def f(x):\n",
    "    return x[0]**2+x[1]**2\n",
    "numerical_gradient(f,np.array([3.0,4.0]))\n",
    "def gradient_descent(f,init_x,lr=0.01,step_num=100):\n",
    "    x=init_x\n",
    "    for i in range(step_num):\n",
    "        grad=numerical_gradient(f,x)\n",
    "        x-=lr*grad\n",
    "    return x\n",
    "init_x=np.array([-3.0,4.0])\n",
    "gradient_descent(f,init_x,step_num=100)\n",
    "x=np.random.normal(0,1,50)\n",
    "y=np.dot(x,5.5)+3\n",
    "y+=np.random.normal(0,2.5,50)\n",
    "plt.scatter(x,y)\n",
    "def get_data():\n",
    "    return x,y\n",
    "#y=wx+b\n",
    "def pred_data(para):\n",
    "    return np.dot(x.reshape(-1,1),para[0])+para[1]\n",
    "para=np.array([7,0.8])\n",
    "para[0]\n",
    "x,y=get_data()\n",
    "yy=pred_data(para)\n",
    "yy.shape\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,yy,'r')\n",
    "def gradient_descent(f,init_x,lr=0.01,step_num=100):\n",
    "    x=init_x\n",
    "    for i in range(step_num):\n",
    "        grad=numerical_gradient(f,x)\n",
    "        x-=lr*grad\n",
    "    return x\n",
    "def mse(para):\n",
    "    return np.sum((y.reshape(-1,1)-pred_data(para))**2)/50\n",
    "para=np.random.randn(2)\n",
    "aa=gradient_descent(mse,para,lr=0.001,step_num=1000)\n",
    "print(aa)\n",
    "mse(para)\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,pred_data(para),'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
